{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\notesum\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import whisper\n",
    "import torchaudio\n",
    "import librosa\n",
    "import os\n",
    "import re\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "# Check if GPU is available \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Limit to 70% of total GPU memory\n",
    "torch.cuda.set_per_process_memory_fraction(0.7, device=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 MB allocated, 0.00 MB reserved\n"
     ]
    }
   ],
   "source": [
    "allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "reserved = torch.cuda.memory_reserved() / 1024**2\n",
    "print(f\"{allocated:.2f} MB allocated, {reserved:.2f} MB reserved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51865, 768)\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_dir = \"./models/whisper\"\n",
    "\n",
    "\n",
    "# Load processor and model\n",
    "ASR_model = whisper.load_model('small', download_root=custom_model_dir)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ASR_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path, chunk_duration_sec=30):\n",
    "    \"\"\"\n",
    "    Transcribe long audio using OpenAI Whisper with manual chunking.\n",
    "    \"\"\"\n",
    "    # Load and resample audio\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # Resample to 16000 Hz\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "        sample_rate = 16000\n",
    "\n",
    "    waveform = waveform.squeeze()  # mono\n",
    "    total_samples = waveform.shape[0]\n",
    "    chunk_size = int(sample_rate * chunk_duration_sec)\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    for start in range(0, total_samples, chunk_size):\n",
    "        end = min(start + chunk_size, total_samples)\n",
    "        chunk = waveform[start:end].cpu().numpy()\n",
    "\n",
    "        # Whisper expects 16-bit float PCM data\n",
    "        audio_np = chunk.astype(\"float32\")\n",
    "\n",
    "        # Transcribe each chunk\n",
    "        result = ASR_model.transcribe(audio_np, language=\"en\")\n",
    "        transcriptions.append(result[\"text\"].strip())\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return \" \".join(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_dir = \"./models/bart\"\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "bart_model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(bart_model_name, cache_dir=custom_model_dir)\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name, cache_dir=custom_model_dir)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bart_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, max_chunk_tokens=512, summary_max_length=150):\n",
    "    \"\"\"Summarize text using BART with chunking.\"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer.encode(current_chunk + sentence, truncation=False)\n",
    "        if len(tokens) <= max_chunk_tokens:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    all_summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(\n",
    "            chunk,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=1024,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            summary_ids = bart_model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_length=summary_max_length,\n",
    "                min_length=30,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=3,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        all_summaries.append(summary)\n",
    "\n",
    "        # Clear memory\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return \"\\n\".join(all_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: I think it's already on actually. God, how do I make this thing work? I've plugged it in the back. Okay, right. Okay. Right. Well, this is the kickoff meeting for our project. Okay. And this is just what we're going to be doing over the next 25 minutes. So first of all, just to kind of make sure that we all know each other, I'm Laura and I'm the project manager. Do you want to introduce yourself again? Hi, I'm David and I'm supposed to be an industrial designer. Okay. And I'm Andrew and I'm a marketing expert. I'm Greg and I'm user interface. Great. OK. So we're designing a new remote control. And oh, I have to record he's here, actually. So that's David, Andrew, and Craig, isn't it? And you all arrived on time. Yes, we did design a new remote control. As you can see, it's supposed to be original, trendy, and user-friendly. So that's kind of our brief. So there are three different stages to the design. I'm not really sure what you guys have already received. In your emails, what did you get? I just got the project announcement. The design remote control. Is that what everybody got? Okay. So we're going to have individual work and then a meeting about it. And repeat that process. three times. At this point you get to try out the whiteboard over there. You get to draw your favorite animal and sum up your favorite characteristics of it. So who would like to go first? I will go. Very good. Alright. So. This one here, right? Okay. Very nice. All right. My favorite animal is like... A beagle. And... Character... favorite characteristics of it? Is that right? Yeah. Right, well, basically, high priority for any animal for me is that they be willing to take a lot of physical affection from their family. And, yeah, they have lots of personality and... be fit and in robust good health. So this is blue. beagle. My family's beagle. Right. Lovely. My favourite animal would be a monkey. A monkey. And then the small cutie and furry. And when plant leaves becomes real, I'm going to be up there with them. You can take as long over this as you like because we haven't got an awful lot to do. It's okay, we do, we do. Don't feel like you're in a rush anyway. I actually told you a whole lot more about beagles. I could do, I'd have to get you. I don't know what mine is, I'm going to have to think in the spotlight. Impressionist. Is that a whale? Yeah. Well, I don't know, it's just the first animal I can think of off the top of my head. The biggest reason is because I'm allergic to most animals. Fish was a natural choice. Yeah, and I kind of like whales. You come in and go, whew. Everything inside. They're quite harmless and mild and interesting. OK. God, I still didn't know what I'm going to write about. Superb sketch, by the way. I was going to choose a dog as well. But I'll just draw a different kind of dog. My favorite animal is my own dog at home. That doesn't really look like him actually. He looks more like a pig actually. I see a dog in there. Oh yeah, that's very good of you. Now I see a rooster. What kind is it? He's a mixture of various things and what do I like about him? That's supposed to suggest that his tail wags. He's very friendly and cheery and always pleased to see you and very kind of affectionate. He's quite wee as well so he doesn't take up... too much space. And he does a funny thing where he chases his tail as well. This is quite amusing. Is he aware that this is his own tail that he's chasing? It is, I think it is. He only does it after he's had his dinner. And all of a sudden he gets up and starts chasing his tail and is trying to live in him. Probably when he was little he got lots of attention for doing it and has forever been conditioned. Where did you find this just down here? Okay. What are we doing next? Okay. We're now going to need to discuss the project finance. So according to the brief, we're going to be selling this remote control for 25 euro, and we're aiming to make... 50 million euro and so we're gonna be selling this on an international scale and We don't want it to cost any more than 1250 euros so 50% of the selling price Can we just go with that again? Sure So basically All right So cost like production cost is all together 1250 but selling price is that wholesale or retail, like on the shelf? I don't know, I imagine that's a good question. Hour of sale, hour of sale. I imagine it probably is hour of sale actually, because it's probably up to the retailer to sell it for whatever price they want. But I don't know, I mean, do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all? I think it will. I'm wondering if there's like with DVD players if there are zones. Oh yeah, regions and stuff. Frequencies or something. Yeah. Okay. As well as characters, different keypad styles and symbols. Yeah. Well, for a remote control, do you think that will be, I suppose it depends on how complicated it is. Okay. So, I'm wondering if there's like a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, about controllers. It does make sense from maybe the design point of view because if you have more complicated characters like European languages then you need more buttons. Yeah. Yeah. And then the other thing, international, is on the topic of price. I'm thinking the price might appeal to a certain market in one region whereas in another it will be different. Just to care about the country. like how much money people have to spend on things. Or just like basic product positioning. A 25-year-old remote control might be a big hit in London. Might not be such a big hit in Greece. Who knows? I see what you're saying. Yeah. Marketing. Good marketing thoughts. Oh gosh, I should be writing all this down. Right away I'm making some kind of assumptions about what information we're giving to the in here thinking, okay, trendy probably means something other than just basic. Yeah. Something other than just standard. So I'm wondering right away is selling 25 euros, is that sort of that? Is this gonna be like the premium product? Yeah, yeah, like how much does, you know, remote control cost? Mm-hm. Well, 25 euro, I mean, that's about like 18 pounds or something, isn't it? Or no, is it as much as that? 17, 18 pounds. I don't know, I've never bought a remote control so I don't know how good a remote control that would get you. But yeah, I suppose it has to look kind of cool and gimmicky. Right, okay. Let me just scoot on ahead here. Okay. Does anybody have anything the finance issue at all? Do we have any other background information on like how that compares to other? No actually that would be useful though wouldn't it if you knew like what your money would get you? No. Yeah, interesting thing about discussing production of remote control for me is that as you point out, I just don't think remote control is being something people consciously assess in their purchasing habits. It's just like getting shoelaces with shoes or something. Five minutes to end of meeting. Okay, we're a bit behind. You know what I mean? one way looking at it would be, well, the people producing television sets, maybe they have to buy remote controls. Or another way is maybe people who have TV sets are really fed up with their remote control and they really want a better one or something. My parents want remote controls because they got fed up of having like four or five different remote controls for each house. Right. Right. So for them it was just how many devices is a control. Right. One of the priorities might be to combine as many. uses. Right. So do you think that should be like a main design aim of our remote control? Do you know your satellite and your regular tally and your VCR and everything? Well like maybe what we could use as a sort of like an example of a successful other piece of technology is Palm Pilots. They're gone from being just like little sort of scribble boards to cameras, MP3 players, telephones, everything, agenda. So like I wonder if we might add something new to the remote. control market such as the lighting in your house or even like you know notes about what you want to watch like you might put in there or I want to watch such and such and look at that's a good idea so extra functionalities. Like personally for me at home I've combined the audio video of my television set and my DVD player and my CD player so they all work actually function together but I have different remote controls for each of them so it's sort of ironic that then they're in there. You know, they sound and everything. It's just one system, but each one's got its own little part. OK. We're going to have to wrap up pretty quickly in the next couple of minutes. I'll just check if nothing else. OK. So anything else anybody wants to add about what they don't like, about remote controls they've used, what they would really like to be. be part of this new one at all. You keep losing them. You keep losing them, OK. Finding them is making a pain, you know. I mean, it's usually quite small. Or when you want it, right? It's at the end of the couch. Yeah. And then at the table. You get those ones where you can, if you whistle or make a really high pitched noise, they beep. I mean, is that something we'd want to include, do you think? I don't know. Sure. OK, maybe. I remember when the first remote control might. My family had was on a cable actually the cable between in the TV and big like buttons that sort of like like on a blender or something My goodness and you know and I think about what they are now is better, but actually it's still kind of I don't know Like a massive junky thing on the table still we could think about how could be more, you know Streamline maybe like a touchscreen or something something like that or whatever would be technologically reasonable Okay that doesn't make it any better, but that just the appeal of not having, you know, these days things in people's homes are becoming more and more like chic, you know, nicer materials and might be worth exploring. Right, well, so it is to wrap up. The next meeting is going to be in 30 minutes, so that's about 10 to 12 by my watch. So in between now and then. As the industrial designer, you're going to be working on the actual working design of it, so you know what you're doing there. For our user interface, technical functions, I guess that's you know, like what we've been talking about, what it'll actually do. And marketing executive, you'll be just thinking about what it actually, what requirements it has to fulfill, and you'll get instructions emailed to you, I guess. Okay. Okay. Yeah, so it's the functional design stages next, I guess. And that's the end of the meeting. I got that little message, a lot of seniors and I thought I would, so. Before we wrap up just to make sure we're all in the same page here. Do we, we're given sort of an example of a coffee machine or something, right? Well, are we right now on the assumption that our television remote control may have features which go beyond the television? Or are we keeping sort of like a design commitment to television features? Okay, well just very quickly because we're supposed to finish now. I guess that's up to us. I mean you probably won't... some kind of unique selling point of it. So, you know... Okay, yeah. Depends on how much you can cram into that price. Okay. Yeah. Right, okay. Well, that's the end of the meeting then. Thank you all for coming. I hope that was what they wanted us to do. Right. Great. How do you turn this thing off? Was it function and... Oh, there we go. I think if you can just leave it on maybe and then... Oh, God. This is time. itself off. Try pushing the function and eat. Oh, there it is. Oh, goodness. Okay. Right. Please. This is all very high tech. I don't know, do you guys go back to your, what do you want to say? Not too long plugging. Good thing we don't have each other capped. Kind of what feels like. I have to do the draft project next semester. This was quite good training. Ah, you didn't mean to do the draft thing when you do. What courses are you taking? Well, I'm talking about new SDP. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I wasn't expecting the five minutes.\n"
     ]
    }
   ],
   "source": [
    "# Sample usage\n",
    "audio_path = \"amicorpus/ES2002a/audio/ES2002a.Mix-Headset.wav\"  # Replace with your actual audio file\n",
    "transcription = transcribe_audio(audio_path)\n",
    "print(\"Transcription:\", transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Project manager: We're designing a new remote control. You get to draw your favorite animal and sum up your favorite characteristics of it. Who would like to go first? I will go.\n",
      "\"I don't know what mine is, I'm going to have to think in the spotlight. Impressionist. Is that a whale? Yeah. The biggest reason is because I'm allergic to most animals\"\n",
      "Do you think the fact that it's going to be sold internationally will have a bearing on how we design it at all? I think it will. I'm wondering if there's like with DVD players if there are zones. Frequencies or something.\n",
      "Remote control is just like getting shoelaces with shoes or something. My parents got fed up of having like four or five different remote controls for each house. One of the priorities might be to combine as many uses.\n",
      "You keep losing them. Finding them is making a pain, you know. I remember when the first remote control was on a cable actually the cable between in the TV and big like buttons that sort of like like on a blender or something. I think about what they are now is better, but actually it's still kind of a massive junky thing on the table still.\n",
      "As the industrial designer, you're going to be working on the actual working design of it, so you know what you're doing there. For our user interface, technical functions, I guess that's you know, like what we've been talking about, what it'll actually do. And marketing executive, you'll be just thinking about what it actually, what requirements it has to fulfill.\n",
      "I wasn't expecting the five minutes. I don't know how long it will take to get to the bottom of this. I'm not sure I want to know. I just want to find out.\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_text(transcription)\n",
    "print(\"Summary:\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
